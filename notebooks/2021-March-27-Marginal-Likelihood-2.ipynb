{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From MML book\n",
    "\n",
    "Definition 6.3 (Expected Value). The expected value of a function $g: \\mathbb{R} \\rightarrow$ $\\mathbb{R}$ of a univariate continuous random variable $X \\sim p(x)$ is given by\n",
    "$$\n",
    "\\mathbb{E}_{X}[g(x)]=\\int_{\\mathcal{X}} g(x) p(x) \\mathrm{d} x\n",
    "$$\n",
    "Correspondingly, the expected value of a function $g$ of a discrete random variable $X \\sim p(x)$ is given by\n",
    "$$\n",
    "\\mathbb{E}_{X}[g(x)]=\\sum_{x \\in \\mathcal{X}} g(x) p(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Nando De Freitas https://www.youtube.com/watch?v=mz3j59aJBZQ&list=PLE6Wd9FR--EdyJ5lbFl8UuGjecvVw66F6&index=16&t=1957s\n",
    "    \n",
    "starting 50 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$I = \\int_{\\mathcal{X}} g(x)p(x)dx = \\dfrac{\\sum_{i=1}^N g(x_i)}{N}$ where $x_i \\sim p(x)$ is a sample from p(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example\n",
    "\n",
    "$X \\sim \\mathcal{N}(0, 1)$\n",
    "\n",
    "$g(x) = x$\n",
    "\n",
    "$\\mathbb{E}_{X}[g(x)] = \\mu = 0$\n",
    "\n",
    "Case II\n",
    "\n",
    "$g(x) = x^2$\n",
    "\n",
    "\n",
    "Now, we know that\n",
    "\n",
    "$\\mathbb{V}_{X}[x]=\\mathbb{E}_{X}\\left[x^{2}\\right]-\\left(\\mathbb{E}_{X}[x]\\right)^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0015121465155362318\n",
      "0.9998449448099948\n",
      "0.9998426582229105\n"
     ]
    }
   ],
   "source": [
    "N = 1000000\n",
    "np.random.seed(0)\n",
    "samples = np.random.normal(loc=0, scale=1, size=N)\n",
    "\n",
    "mu_hat = np.mean(samples)\n",
    "print(mu_hat)\n",
    "\n",
    "\n",
    "exp_x2 = np.mean(np.square(samples))\n",
    "print(exp_x2)\n",
    "\n",
    "var = np.var(samples)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can similarly approximate the marginal likelihood as follows:\n",
    "\n",
    "Marginal likelihood = $\\int_{\\mathcal{\\theta}} P(D|\\theta) P(\\theta)d\\theta = I = \\dfrac{\\sum_{i=1}^N P(D|\\theta_i)}{N}$ where $\\theta_i$ is drawn from $p(\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "    \n",
    "Linear regression in say two variables. Prior is $p(\\theta)\\sim \\mathcal{N}([0, 0]^T, I)$. We can easily draw samples from this prior then the obtained sample can be used to calculate the likelihood. The marginal likelihood is the empirical mean of likelihoods derived in this way."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
